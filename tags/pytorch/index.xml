<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pytorch | pvnieo</title>
    <link>https://pvnieo.github.io/tags/pytorch/</link>
      <atom:link href="https://pvnieo.github.io/tags/pytorch/index.xml" rel="self" type="application/rss+xml" />
    <description>Pytorch</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2020 Souhaib Attaiki, made with lots of ❤️ and steaming hot ☕️.</copyright><lastBuildDate>Sat, 10 Aug 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://pvnieo.github.io/img/icon.png</url>
      <title>Pytorch</title>
      <link>https://pvnieo.github.io/tags/pytorch/</link>
    </image>
    
    <item>
      <title>How to use the Learning Rate Finder in Pytorch</title>
      <link>https://pvnieo.github.io/post/lr-finder-demo/</link>
      <pubDate>Sat, 10 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://pvnieo.github.io/post/lr-finder-demo/</guid>
      <description>&lt;h1 id=&#34;learning-rate-finder&#34;&gt;Learning rate finder&lt;/h1&gt;

&lt;p&gt;During the training of neural networks, one of the most important hyperparameters, and which largely influences the convergence of the latter, is the learning rate. Choosing a good learning rate is not a simple task, and it is often done using a grid search. However, this can take a long time, especially if the network is very large.&lt;/p&gt;

&lt;p&gt;In his paper &amp;quot;&lt;a href=&#34;https://arxiv.org/pdf/1506.01186.pdf&#34;&gt;Cyclical Learning Rates for Training Neural Networks&lt;/a&gt;&amp;quot;, Leslie Smith presented a method for finding a good learning rate for the majority of gradient based optimizers.&lt;/p&gt;

&lt;p&gt;This method consists in starting the training of the network with a very small learning rate (10-8 for example), and increasing it exponentially with each mini-batch, until reaching a large value (1 or 10), or until the loss diverges (practically, we stop the loop if the loss reached is 4 or 5 times greater than the minimum loss we obtained).&lt;/p&gt;

&lt;p&gt;At the end of the loop, a learning rate is chosen in the region where the loss was minimal. In practice, we take a value an order of magnitude smaller than the one that gave the minimum loss, a value that is always aggressive (to train quickly) but that remains safe in case of an explosion.&lt;/p&gt;

&lt;p&gt;In the following, we will demonstrate the usefulness of this method by using an implementation of this method that we have done. You can find this implementation &lt;a href=&#34;https://github.com/pvnieo/My-Algorithm-Zoo/blob/master/Learning%20rate%20finder/lr_finder.py&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;demo-time&#34;&gt;Demo time&lt;/h2&gt;

&lt;p&gt;First of all, let&#39;s start by importing the necessary packages.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# stdlib
import time
import warnings
import copy
from collections import defaultdict
# 3p
import numpy as np
from tabulate import tabulate
import matplotlib.pyplot as plt
from tqdm import tqdm
import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

# project
from lr_finder import LRFinder

warnings.filterwarnings(&#39;ignore&#39;)
%reload_ext autoreload
%autoreload 2
%matplotlib inline&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this demonstration, we will use the MNIST dataset, and we will implement a very simple neural network using pytorch.&lt;/p&gt;

&lt;p&gt;First of all, we define the data loaders and the transformations we will use later.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;batch_size_train = 64
batch_size_test = 1000
## creating dataloaders
train_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST(&#39;/files/&#39;, train=True, download=True,
                             transform=torchvision.transforms.Compose([
                             torchvision.transforms.ToTensor(),
                             torchvision.transforms.Normalize(
                               (0.1307,), (0.3081,))
                             ])),
  batch_size=batch_size_train, shuffle=True)

val_loader = torch.utils.data.DataLoader(
  torchvision.datasets.MNIST(&#39;/files/&#39;, train=False, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (0.1307,), (0.3081,))
                             ])),
  batch_size=batch_size_test, shuffle=True)
dataloaders = {&#34;train&#34;: train_loader, &#34;val&#34;: val_loader}&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;examples = enumerate(val_loader)
batch_idx, (example_data, example_targets) = next(examples)
fig = plt.figure()
for i in range(6):
  plt.subplot(2,3,i+1)
  plt.tight_layout()
  plt.imshow(example_data[i][0], cmap=&#39;gray&#39;, interpolation=&#39;none&#39;)
  plt.title(&#34;Ground Truth: {}&#34;.format(example_targets[i]))
  plt.xticks([])
  plt.yticks([])
fig&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./demo_5_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./demo_5_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;Now let&#39;s build the network. We will use a simple network, with three convolution layers, and two fully connected layers.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## build the network
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will use the CrossEntropyLoss as a loss because we are facing a classification task, and we will use the famous SGD optimizer to optimize the network.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.001)
device = torch.device(&#34;cuda:0&#34; if torch.cuda.is_available() else &#34;cpu&#34;)
criterion = nn.CrossEntropyLoss().to(device)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let&#39;s define a helper method that will train the model&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def train_model(model, criterion, optimizer, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):

        # Each epoch has a training and validation phase
        for phase in [&#39;train&#39;, &#39;val&#39;]:
            if phase == &#39;train&#39;:
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == &#39;train&#39;):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == &#39;train&#39;:
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)


            # deep copy the model
            if phase == &#39;val&#39; and epoch_acc &gt; best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())


    time_elapsed = time.time() - since

    # load best model weights
    model.load_state_dict(best_model_wts)
    return best_acc.item()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to evaluate this method, we will train the same network several times, using the same hyperparameters, but only change the learning rate. First we will launch the learning rate finder method to find the optimal learning rate.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;model = Net()
optimizer = optim.SGD(model.parameters(), lr=0.1)
lr_finder = LRFinder(model, optimizer, criterion)
lr_finder.find(train_loader)
plt.figure(figsize=(6,6))
lr_finder.plot()&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt; 89%|████████▉ | 89/100 [00:00&lt;00:00, 91.63it/s]


LR Finder is complete. See the graph using `.plot()` method.
Min numerical gradient: 0.39810717055349676
Min loss: 0.7585775750291828&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./demo_13_2.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;After observing the graph, and following the instructions mentioned above, we will choose the value 0.1 for the learning rate.
As a result, we will compare this value with other learning rate values which are 1e-4, 1e-3, 1e-2, 1 and 10. For each value, we will train the model 5 times, and we will record the average value of the accuracy obtained. The results will be summarized in a table below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lrs = [1e-4, 1e-3, 1e-2, 0.1, 1, 10]
repeat = 5
accs = defaultdict(list)
for lr in tqdm(lrs):
    for _ in range(repeat):
        model = Net().to(device)
        optimizer = optim.SGD(model.parameters(), lr=lr)
        acc = train_model(model, criterion, optimizer, num_epochs=3)
        accs[lr].append(acc)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;  0%|          | 0/6 [00:00&lt;?, ?it/s]
 17%|█▋        | 1/6 [02:43&lt;13:38, 163.62s/it]
 33%|███▎      | 2/6 [05:26&lt;10:53, 163.29s/it]
 50%|█████     | 3/6 [08:08&lt;08:08, 162.99s/it]
 67%|██████▋   | 4/6 [10:50&lt;05:25, 162.65s/it]
 83%|████████▎ | 5/6 [13:34&lt;02:43, 163.02s/it]
100%|██████████| 6/6 [16:18&lt;00:00, 163.38s/it]&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;means = [&#34;means&#34;] + [np.mean(accs[lr]) for lr in lrs]
stds = [&#34;stds&#34;] + [np.std(accs[lr]) for lr in lrs]
print(tabulate([means, stds], headers=[&#34;lrs&#34;] + lrs))&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;lrs       0.0001      0.001        0.01         0.1           1          10
-----  ---------  ---------  ----------  ----------  ----------  ----------
means  0.17946    0.74826    0.95522     0.98172     0.1073      0.10414
stds   0.0407632  0.0746226  0.00278381  0.00141619  0.00759342  0.00507685&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Et Voila! as we can see, the learning rate suggested by lr_finder gives the best result.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ManGan</title>
      <link>https://pvnieo.github.io/project/mangan/</link>
      <pubDate>Sat, 02 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://pvnieo.github.io/project/mangan/</guid>
      <description>&lt;p&gt;This project aims to color black and white mangap ages, based on the corresponding anime adaptation, using Generative Adversarial Nets.&lt;/p&gt;
&lt;p&gt;For the moment, two types of GANs have been tested: &lt;a href=&#34;https://arxiv.org/pdf/1611.07004.pdf&#34;&gt;pix2pix&lt;/a&gt; and &lt;a href=&#34;https://arxiv.org/pdf/1703.10593.pdf&#34;&gt;cycle-gan&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For more information about our method, see the &lt;a href=&#34;https://www.researchgate.net/publication/331175026_Manga_Colorization_using_Generative_Adversarial_Nets&#34;&gt;Project Report&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some of the results obtained are displayed in the following image:
&lt;img src=&#34;results.jpeg&#34; alt=&#34;GitHub Logo&#34;&gt;&lt;/p&gt;
&lt;p&gt;This project is &lt;strong&gt;under development&lt;/strong&gt;, currently, there are diffuclties to color images containing text.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
